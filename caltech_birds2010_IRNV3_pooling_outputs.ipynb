{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "caltech_birds2010_IRNV3_pooling_outputs",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCZTSQZ-q7U-",
        "colab_type": "text"
      },
      "source": [
        "## Identifying bird species using InceptionResNetV2-based model\n",
        "---\n",
        "The *inception* architechture introduce in 2013 (?) by researchers at Google is excellent for classifying images where the subject is likely to appear in various sizes/positions in the image data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pToeNxjzrvBc",
        "colab_type": "text"
      },
      "source": [
        "### $\\S$ 0: Data preparation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7gKZvmpWleF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "00e86710-f106-4a05-d28d-c43674d6b03d"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "# Choose whether to use the training or validation subsets\n",
        "SUBSET = \"training\"\n",
        "\n",
        "# If subset == 'training', opt for the larger of both values below\n",
        "\n",
        "def get_data(subset, seed=0, **kwargs):\n",
        "    \"\"\"\n",
        "    \n",
        "    This function uses ImageDataGenerator to produce data from google drive\n",
        "    \n",
        "    \"\"\"\n",
        "    total_images, batch_size = {\n",
        "\n",
        "        \"training\":[5095,11],\n",
        "        \"validation\":[856,8]\n",
        "\n",
        "    }.get(subset)\n",
        "\n",
        "\n",
        "    # Generator to augment our training images\n",
        "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        validation_split=0.16,\n",
        "        **kwargs # Allow for additional augmentation parameters\n",
        "    )\n",
        "\n",
        "    flow = datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/caltech_birds2010/',\n",
        "        shuffle=False,\n",
        "        target_size=(299,299),\n",
        "        batch_size=batch_size,\n",
        "        subset=subset,\n",
        "        seed=seed\n",
        "    )\n",
        "\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # Iterate through our directory using .next()\n",
        "    for i in range(total_images // batch_size):\n",
        "\n",
        "        # Save the images and labels separately\n",
        "        image_batch, label_batch = flow.next()\n",
        "\n",
        "        # Convert from (batch_size, <# of classes>) to (batch_size,)\n",
        "        label_batch = [label.argmax for label in label_batch]\n",
        "\n",
        "        # Add the images/labels from our data generator to a list\n",
        "        images.extend(image_batch)\n",
        "        labels.extend(label_batch)\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f\"Complete {i+1}/{total_images//batch_size}\")\n",
        "\n",
        "    print(\"Finished loading images from data generator\")\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "\n",
        "# Get test data\n",
        "test_images, test_labels = get_data(subset=\"validation\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 856 images belonging to 200 classes.\n",
            "Complete {i+1}/{total_images//batch_size}\n",
            "Complete {i+1}/{total_images//batch_size}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq-chsIfJiFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get training data\n",
        "images, labels = get_data(\"training\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ_BuaV5KCTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Show a few example images\n",
        "\n",
        "plt.figure(figsize=(8,5),dpi=100)\n",
        "\n",
        "example1, example2 = images[-1], images[-2]\n",
        "\n",
        "ax1 = plt.subplot(1,2,1)\n",
        "ax2 = plt.subplot(1,2,2)\n",
        "\n",
        "ax1.imshow(example1)\n",
        "ax2.imshow(example2);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stL02iWlr6UA",
        "colab_type": "text"
      },
      "source": [
        "### $\\S$ 1: Model architechture\n",
        "\n",
        "Below is a graphic showing the model design which will serve as the base for our classifier:\n",
        "\n",
        "[image](https://1.bp.blogspot.com/-O7AznVGY9js/V8cV_wKKsMI/AAAAAAAABKQ/maO7n2w3dT4Pkcmk7wgGqiSX5FUW2sfZgCLcB/s1600/image00.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDXQwDPbGE2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "\n",
        "# Whether to use the 'max' pooling or 'avg' pooling layer as output\n",
        "POOLING = 'avg'\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "base_model = InceptionResNetV2(\n",
        "    include_top=False,\n",
        "    pooling=POOLING\n",
        ")\n",
        "\n",
        "print(f\"Number of model layers: {len(base_model.layers)}\")\n",
        "print(f\"Output shape: {base_model.output.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtvXFGwlcoE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "\n",
        "\n",
        "# Whether or not to truncate the base model further, and how deep/shallow\n",
        "LITE = True\n",
        "DEPTH = 2 # there are three options: 1,2, and 3\n",
        "\n",
        "\n",
        "if LITE:\n",
        "\n",
        "    output_layer = 'max_pooling2d_'+str(DEPTH)\n",
        "\n",
        "    base_model = Model(\n",
        "        inputs=base_model.input,\n",
        "        outputs=base_model.get_layer(output_layer).output\n",
        "    )\n",
        "\n",
        "    print(f\"Number of model layers: {len(base_model.layers)}\")\n",
        "    print(f\"Output shape: {base_model.output.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzOHrAKzeJRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inspect the shape of our resulting tensor\n",
        "\n",
        "print(\"Shape of our dataset\")\n",
        "images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZRYg5oTQxxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use our model to predict on the image data\n",
        "\n",
        "pooling_outputs = base_model.predict(\n",
        "    images,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(f\"Completed inference on dataset\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr295XgHjA4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_shape = pooling_outputs.shape\n",
        "print(f\"Shape of pooling_outputs: {output_shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLoLJ_UgRB65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the model outputs if they aren't 1D tensors\n",
        "\n",
        "if LITE:\n",
        "\n",
        "    # Compare bird images to the sum of their pooling outputs\n",
        "    BIRD = 12\n",
        "\n",
        "    plt.figure(figsize=(8,5),dpi=100)\n",
        "\n",
        "    ax1 = plt.subplot(1,2,1)\n",
        "    ax2 = plt.subplot(1,2,2)\n",
        "\n",
        "    ax1.imshow(images[BIRD])\n",
        "    ax2.imshow(pooling_outputs[BIRD].sum(axis=-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrnseiCNs3RA",
        "colab_type": "text"
      },
      "source": [
        "#### Adding trainable layers to this model in order to fine-tune it's performance for our specific use case\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoyosEwotBCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense,Dropout,Flatten\n",
        "\n",
        "\n",
        "# Freeze our base model so only the weights of our final layers can be trained\n",
        "for layer in base_model.layers:\n",
        "    model.trainable = False\n",
        "\n",
        "\n",
        "# Create a block of dense/dropout layers to add to our dase\n",
        "inputs = base_model.output\n",
        "x = Flatten()(inputs)\n",
        "x = Dense(1200,activation='relu')(x)\n",
        "x = Dropout(.2)(x)\n",
        "x = Dense(300)(x)\n",
        "x = Dropout(.2)(x)\n",
        "outputs = Dense(200,activation='softmax')(x)\n",
        "\n",
        "\n",
        "# Final classification model\n",
        "model = Model(inputs,outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RfcVGAFviCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the specifications for any callback function you want to include\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.2,\n",
        "    patience=5, min_lr=0.001\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Chose the optimizer and loss function for this model\n",
        "\n",
        "OPTIMIZER = tf.keras.optimizers.SGD(lr = 0.003)\n",
        "LOSS = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=OPTIMIZER,\n",
        "    loss=LOSS,\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWXGgHcn0rN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "epochs = 2\n",
        "shuffle = True\n",
        "\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    [images,labels],\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    shuffle=shuffle,\n",
        "    callbacks=[reduce_lr],\n",
        "    validation_data=[test_images,test_labels]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}